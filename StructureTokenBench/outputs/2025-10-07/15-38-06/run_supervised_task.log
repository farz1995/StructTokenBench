[2025-10-07 15:38:06,441][util][INFO] - Configuration args
[2025-10-07 15:38:06,442][util][INFO] - {'model': {'class_name': 'ZeroShotCodebookUtilityModel', 'pretrained_ckpt_path': '', 'ckpt_path': None, 'num_labels': 1, 'dropout': 0.1, 'num_layer': 1, 'hidden_size': 512, 'num_tokens': None, 'd_model': None, 'is_global_or_local': 'local', 'multi_label': False, 'regression': False, 'use_sequence': False, 'sequence_only': False, 'add_noise': None, 'task_goal': 'codebook_utilization'}, 'deepspeed_path': 'src/script/config/deepspeed/32_stage2.json', 'default_data_dir': '/home/fe5vb/project/PST/struct_token_bench_release_data', 'tokenizer': 'stb_tokenizers.wrapped_myrep.WrappedMyRepTokenizer', 'tokenizer_pretrained_ckpt_path': None, 'tokenizer_ckpt_name': None, 'max_steps': 10000, 'experiment_name': 'test', 'run_name': 'myrep_casp14_util', 'validate_only': False, 'test_only': True, 'save_dir_path': '', 'tokenizer_device': 'cuda', 'precompute_tokens': True, 'quantizer_use_linear_project': False, 'model_encoder_dmodel': 1024, 'model_encoder_nlayers': 2, 'model_encoder_vheads': 128, 'quantizer_codebook_size': 4096, 'quantizer_codebook_embed_size': 128, 'model_encoder_dout': 128, 'trainer': {'accelerator': 'gpu', 'num_nodes': 1, 'check_val_every_n_epoch': 1, 'default_root_dir': '/home/fe5vb/project/PST/struct_token_bench_logs', 'enable_checkpointing': True, 'enable_model_summary': True, 'enable_progress_bar': True, 'devices': 1, 'gradient_clip_val': 1.0, 'limit_train_batches': None, 'limit_val_batches': None, 'log_every_n_steps': 20, 'max_epochs': None, 'max_steps': 10000, 'num_sanity_val_steps': 0, 'precision': '32-true', 'reload_dataloaders_every_n_epochs': 1, 'val_check_interval': 1.0, 'accumulate_grad_batches': 1, 'deterministic': True}, 'lightning': {'model_module': {'_target_': 'model_module.PlModel', 'py_logger': None, 'optimizer_cfg': None, 'model_cfg': None}, 'data_module': {'_target_': 'data_module.ProteinDataModule'}, 'callbacks': {'checkpoint': {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'every_n_train_steps': None, 'every_n_epochs': 1, 'save_top_k': 3, 'monitor': 'validation_f1_score', 'mode': 'max', 'filename': '{epoch}-{step}-{validation_f1_score:.2f}', 'save_last': True, 'dirpath': None}, 'lr_monitor': {'_target_': 'pytorch_lightning.callbacks.LearningRateMonitor', 'logging_interval': 'step'}, 'progress_bar': {'_target_': 'pytorch_lightning.callbacks.progress.TQDMProgressBar', 'refresh_rate': 10}}, 'logger': {'_target_': 'pytorch_lightning.loggers.TensorBoardLogger', 'save_dir': '/home/fe5vb/project/PST/struct_token_bench_logs', 'name': 'test'}, 'strategy': 'auto'}, 'data': {'num_workers': 0, 'prefetch_factor': None, 'data_path': '/home/fe5vb/project/PST/struct_token_bench_release_data/data/utility', 'data_name': 'CASP14Dataset', 'target_field': None, 'filter_length': 600, 'truncation_length': 5000, 'multi_label': False, 'is_global_or_local': 'local', 'pdb_data_dir': None, 'use_continuous': False, 'use_sequence': False}, 'optimization': {'micro_batch_size': 8, 'seed': 1234, 'optimizer': {'name': 'adam', 'lr': 0.0002, 'betas': [0.9, 0.98], 'eps': 1e-08, 'adam_w_mode': True, 'weight_decay': 0.01, 'params': None}, 'scheduler': {'_target_': 'util.get_cosine_schedule_with_warmup', 'optimizer': None, 'min_ratio': 0.1, 'plateau_ratio': 0.1, 'num_warmup_steps': 200, 'num_training_steps': 10000}, 'override': {'mult_factor': 1.0, 'add_index': 0}}, 'autorestart': {'filter_keywords': ['last.ckpt']}, 'tokenizername': 'myrep'}
[2025-10-07 15:38:06,442][root][INFO] - Training with 1 nodes micro-batch size 8 total batch size 8 and 1 devices per-node
